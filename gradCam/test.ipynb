{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgROI(parentFolderDir: str, subj: int, fmriData, hemi: str = \"l\"):\n",
    "    rois = np.array([\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\", \"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\", \"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\", \"OPA\", \"PPA\", \"RSC\", \"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\", \"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"])\n",
    "    avgRoiValues = np.zeros((len(fmriData), len(rois)))\n",
    "    for i in range(len(rois)):\n",
    "        roi = rois[i]\n",
    "        if roi in [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\"]:\n",
    "            roi_class = 'prf-visualrois'\n",
    "        elif roi in [\"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\"]:\n",
    "            roi_class = 'floc-bodies'\n",
    "        elif roi in [\"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\"]:\n",
    "            roi_class = 'floc-faces'\n",
    "        elif roi in [\"OPA\", \"PPA\", \"RSC\"]:\n",
    "            roi_class = 'floc-places'\n",
    "        elif roi in [\"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\"]:\n",
    "            roi_class = 'floc-words'\n",
    "        elif roi in [\"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"]:\n",
    "            roi_class = 'streams'\n",
    "        roiMap = np.load(f\"{parentFolderDir}/subj0{subj}/roi_masks/mapping_{roi_class}.npy\", allow_pickle=True).item()\n",
    "        challenge_roi_class = np.load(f\"{parentFolderDir}/subj0{subj}/roi_masks/{hemi}h.{roi_class}_challenge_space.npy\")\n",
    "        # Select the vertices corresponding to the ROI of interest\n",
    "        roi_mapping = list(roiMap.keys())[list(roiMap.values()).index(roi)]\n",
    "        challenge_roi = np.asarray(challenge_roi_class == roi_mapping, dtype=int)\n",
    "        # print(roi_mapping)       \n",
    "        vals = fmriData[:,np.where(challenge_roi)[0]].mean(axis = 1)\n",
    "        avgRoiValues[:, i] = vals\n",
    "    mask = np.arange(len(avgRoiValues[0]))\n",
    "    print(mask)\n",
    "    mask = mask[~np.isnan(avgRoiValues.max(axis=0))]\n",
    "    print(mask)\n",
    "    return rois[mask], avgRoiValues[:, mask]\n",
    "\n",
    "class AlgonautsDataset(Dataset):\n",
    "    def __init__(self, parentDir: str, subj: int, dataIdxs: list = None, transform = None):\n",
    "        self.imagesPath = os.path.join(parentDir, f\"subj0{subj}/training_split/training_images/\")\n",
    "        self.fmriPath = os.path.join(parentDir, f\"subj0{subj}/training_split/training_fmri/\")\n",
    "        self.imagePaths = np.array(os.listdir(self.imagesPath))\n",
    "        self.lhFMRI = np.load(os.path.join(self.fmriPath, \"lh_training_fmri.npy\"))\n",
    "        self.rhFMRI = np.load(os.path.join(self.fmriPath, \"rh_training_fmri.npy\"))\n",
    "        self.lhROIs, self.lhAvgFMRI = getAvgROI(parentDir, subj, self.lhFMRI)\n",
    "        self.rhROIs, self.rhAvgFMRI = getAvgROI(parentDir, subj, self.rhFMRI, hemi=\"r\")\n",
    "        self.transform = transform\n",
    "        if dataIdxs is not None:\n",
    "            self.imagePaths = self.imagePaths[dataIdxs]\n",
    "            self.lhFMRI = self.lhFMRI[dataIdxs]\n",
    "            self.rhFMRI = self.rhFMRI[dataIdxs]\n",
    "            self.lhAvgFMRI = self.lhAvgFMRI[dataIdxs]\n",
    "            self.rhAvgFMRI = self.rhAvgFMRI[dataIdxs]\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        imagePath = os.path.join(self.imagesPath, self.imagePaths[idx])\n",
    "        image = Image.open(imagePath)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        lh, rh = self.lhFMRI[idx], self.rhFMRI[idx]\n",
    "        avgLh, avgRh = self.lhAvgFMRI[idx], self.rhAvgFMRI[idx]\n",
    "        return image, imagePath, torch.tensor(lh, dtype=torch.float32), torch.tensor(rh, dtype=torch.float32), torch.tensor(avgLh, dtype=torch.float32), torch.tensor(avgRh, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentDir = \"C:/Users/josem/Documents/schoolWork/MQP/algonauts2023_transformers#2Leader/algonauts_2023_challenge_data/\"\n",
    "tsfms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem\\AppData\\Local\\Temp\\ipykernel_36968\\3170735659.py:24: RuntimeWarning: Mean of empty slice.\n",
      "  vals = fmriData[:,np.where(challenge_roi)[0]].mean(axis = 1)\n",
      "c:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30]\n",
      "[ 0  1  2  3  4  5  6  7  8 11 12 16 17 18 19 20 21 22 24 25 26 27 28 29\n",
      " 30]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 16 17 18 19 20 21 24 25 26 27 28\n",
      " 29 30]\n"
     ]
    }
   ],
   "source": [
    "dataset = AlgonautsDataset(parentDir, 1, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8907f5995ab74a6cd5df9da2d2bcd12f57f5b23c9c38358337eeb837f01ad676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
